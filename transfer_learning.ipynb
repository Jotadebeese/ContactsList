{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jotadebeese/ContactsList/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRdgwjgQwkTL"
      },
      "source": [
        "# Transfer Learning with PyTorch\n",
        "\n",
        "The following is the implementation of transfer learning for a Computer Vision classification application using torchvision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LKfBv1WcwkTN",
        "outputId": "d8564c97-cf35-49f9-9ac2-4c81102b0ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find scripts, downloading them from GitHub.\n",
            "Cloning into 'pytorch_scripts'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 67 (delta 32), reused 60 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (67/67), 20.30 KiB | 10.15 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ],
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo, installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the PyTorch Scripts directory, download it from GitHub\n",
        "try:\n",
        "    from modular_scripts import data_setup, engine\n",
        "except:\n",
        "    # Get the scripts\n",
        "    print(\"[INFO] Couldn't find scripts, downloading them from GitHub.\")\n",
        "    !git clone https://github.com/Jotadebeese/pytorch_scripts\n",
        "    !mv pytorch_scripts/modular_scripts .\n",
        "    !rm -rf pytorch_scripts\n",
        "    from modular_scripts import data_setup, engine, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Z2_scOwkTO"
      },
      "source": [
        "## 1. Get data\n",
        "\n",
        "Getting data using the function `get_data` from `utils.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7IasWGVtwkTO",
        "outputId": "65c24df1-bb3c-4dab-89e7-e0b0caa9e153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data/images_dataset' does not exist, creating directory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17oNGRMw72dcTOhbm_H4Gu7GrCx_LPpVp\n",
            "To: /content/data/dataset.zip\n",
            "100%|██████████| 549M/549M [00:06<00:00, 82.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping data...\n"
          ]
        }
      ],
      "source": [
        "image_path = utils.get_data(zip_file_id='17oNGRMw72dcTOhbm_H4Gu7GrCx_LPpVp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeEnZH_swkTP"
      },
      "source": [
        "### 1.1 Converting Images to jpg format\n",
        "\n",
        "Converting images to jpg using `image_convertor` from `utils`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jmoYurJSwkTP",
        "outputId": "eab52a99-fd7e-48c0-c43b-11a068ad9e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "492it [00:03, 133.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66 images converted to 'jpg' in 'data/rubbish_dataset/cardboard'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "772it [00:02, 369.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 images converted to 'jpg' in 'data/rubbish_dataset/glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "672it [00:00, 91080.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 images converted to 'jpg' in 'data/rubbish_dataset/metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "743it [00:00, 91655.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 images converted to 'jpg' in 'data/rubbish_dataset/paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "632it [00:00, 80133.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 images converted to 'jpg' in 'data/rubbish_dataset/plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "456it [00:05, 76.02it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125 images converted to 'jpg' in 'data/rubbish_dataset/trash'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# cardboard class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/cardboard/\",\n",
        "                    format=\"jpg\")\n",
        "# glass class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/glass/\",\n",
        "                    format=\"jpg\")\n",
        "# metal class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/metal/\",\n",
        "                    format=\"jpg\")\n",
        "# paper class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/paper/\",\n",
        "                    format=\"jpg\")\n",
        "# plastic class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/plastic/\",\n",
        "                      format=\"jpg\")\n",
        "# trash class convertion\n",
        "utils.image_convertor(path=\"data/rubbish_dataset/trash/\",\n",
        "                      format=\"jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCW2oGrwkTP"
      },
      "source": [
        "### 1.2 Spliting Data into train, validation and test\n",
        "\n",
        "Using `split folders`\n",
        "\n",
        "Source: https://github.com/jfilter/split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMsvSMP_wkTP",
        "outputId": "3c70359d-c233-4498-e754-8afeb43ded2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders[full]\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from split-folders[full]) (4.66.1)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 3767 files [00:02, 1843.22 files/s]\n"
          ]
        }
      ],
      "source": [
        "# get split-folders ready to use\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    import splitfolders\n",
        "except:\n",
        "    !pip install split-folders[full]\n",
        "    import splitfolders\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = \"data/rubbish_dataset\"\n",
        "output_folder = str(image_path)\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output_folder,\n",
        "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values\n",
        "\n",
        "shutil.rmtree(input_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QcXjcMvywkTP",
        "outputId": "885195ea-d556-4588-8bcb-733f21c4ad92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/images_dataset/train'),\n",
              " PosixPath('data/images_dataset/test'),\n",
              " PosixPath('data/images_dataset/val'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Setup directory path\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "val_dir = image_path / \"val\"\n",
        "\n",
        "train_dir, test_dir, val_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx9Tn2dJwkTQ"
      },
      "source": [
        "## 2. Create Datasets and DataLoaders\n",
        "\n",
        "To do so, we use `data_setup.py` and the `create_dataLoaders()` inside it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdpNKezrwkTQ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}